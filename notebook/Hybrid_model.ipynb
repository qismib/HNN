{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTROL PARAMETERS CELL\n",
    "\n",
    "name = [\"Lagos\",\"Perth\"]\n",
    "seed = 25\n",
    "\n",
    "split_size = 0.8\n",
    "batch_size =  40\n",
    "\n",
    "n_qubits = 2\n",
    "\n",
    "hidden_layers =  [4]\n",
    "dropout = [0.]\n",
    "learning_rate = 5e-5\n",
    "\n",
    "step_size = 50\n",
    "gamma = 0.75\n",
    "\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "data = np.load('Dati/dataset_{}_x_{}_1000.npy'.format(name[0],name[1]))\n",
    "label = np.load('Dati/labels_{}_x_{}_1000.npy'.format(name[0],name[1]))\n",
    "\n",
    "indices = np.random.permutation(data.shape[0])\n",
    "data = data[indices]\n",
    "label = label[indices]\n",
    "\n",
    "data = torch.tensor(data, dtype=torch.float32)\n",
    "label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "label = torch.reshape(label, [label.shape[0], 1])\n",
    "\n",
    "print( len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(data,label)\n",
    "train_size = int( split_size * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, worker_init_fn= np.random.seed(seed) )\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False , worker_init_fn= np.random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch')\n",
    "def ZeroEntanlerCircuit(inputs, weights):\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), pad_with=0.0, normalize= True)\n",
    "    for i in range(n_qubits):\n",
    "        qml.RX(weights[i] , wires=i)\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "weight_shapes = {\"weights\": (n_qubits,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch')\n",
    "def EntanlerCircuit(inputs, weights):\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), pad_with=0.0, normalize= True)\n",
    "    for i in range(n_qubits):\n",
    "        qml.RX(weights[i] , wires=i)\n",
    "\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\"weights\": (n_qubits,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#qlayer = qml.qnn.TorchLayer( ZeroEntanlerCircuit, weight_shapes)\n",
    "qlayer = qml.qnn.TorchLayer( EntanlerCircuit, weight_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockLayer(torch.nn.Module):\n",
    "    def __init__(self,input_feat, output_feat, d_out):\n",
    "        super(BlockLayer,self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Linear( input_feat, output_feat),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout( d_out )\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HybridNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_layers, d_out):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        self.layers.append( torch.nn.Linear( len(data[0])  , hidden_layers[0]) )\n",
    "        self.layers.append(torch.nn.ReLU())\n",
    "        self.layers.append(torch.nn.Dropout(d_out[0]))\n",
    "\n",
    "        for i in range (len(hidden_layers) - 1):\n",
    "            self.layers.append( BlockLayer( hidden_layers[i], hidden_layers[i+1], d_out[i+1]) )\n",
    "\n",
    "        last_layer_len = len(hidden_layers) - 1\n",
    "        self.layers.append( torch.nn.Linear( hidden_layers[last_layer_len], n_qubits) )\n",
    "        self.layers.append(torch.nn.Tanh())\n",
    "        self.layers.append(qlayer)\n",
    "        self.layers.append(torch.nn.Linear(n_qubits,1))\n",
    "\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, qml.qnn.TorchLayer):\n",
    "                torch.nn.init.uniform_(layer.weights, -np.pi, np.pi)\n",
    "                break   \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "      \n",
    "      \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_he(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')  # Inizializzazione He (normale)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)  # Inizializza i bias a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridNetwork( hidden_layers , dropout )\n",
    "model.apply(init_weights_he)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "lossFunction = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size= step_size, gamma= gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model( model , loader , loss_fn  ):\n",
    "    \n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for id, (data, label) in enumerate(loader):\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output,label)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            prob = torch.sigmoid(output)\n",
    "            all_outputs.append(prob)\n",
    "            all_labels.append(label)\n",
    "\n",
    "        losses = running_loss/(id+1)\n",
    "        all_outputs_tensor = torch.cat(all_outputs)\n",
    "        all_labels_tensor = torch.cat(all_labels)\n",
    "\n",
    "        predicted = torch.round(all_outputs_tensor)\n",
    "       \n",
    "        accuracy = accuracy_score(all_labels_tensor.numpy(), predicted.numpy())\n",
    "\n",
    "        return accuracy , losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual model training (and validation). It may take a while, depending on:\n",
    "# epoch number, network architecture, dataset size.\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "# training the model\n",
    "for i in range(epochs):\n",
    "\n",
    "    train_running_loss = 0\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "    for id_batch, (data, label) in enumerate(train_loader):\n",
    "        output = model(data)\n",
    "        loss = lossFunction(output, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "   \n",
    "    train_losses.append(train_running_loss/(id_batch+1))\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    train_acc , train_loss = evaluate_model( model , train_loader, lossFunction)\n",
    "    val_acc , val_loss = evaluate_model( model , val_loader, lossFunction)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "      \n",
    "    if (i+1)%10==0 :\n",
    "        print(\n",
    "            \"Epoch: {}\\tTraining Loss: {:.4f}\\tVal Loss: {:.4f}\\tTraining Accuracy: {:.2f}%\\tValidation Accuracy: {:.2f}%\".format(\n",
    "                i + 1, train_losses[i], val_loss, 100 * train_acc, 100 * val_acc)\n",
    "            )\n",
    "    \n",
    "print(' ')\n",
    "print( f'train parameter: ')\n",
    "print(f'batch_size: {batch_size} \\t hidden layer: {hidden_layers} \\t dropout: {dropout}')\n",
    "print(f'lr: {learning_rate} \\t step size: {step_size} \\t gamma: {gamma}')\n",
    "print(f'epochs: {epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*max(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend([\"Loss on train\", \"Loss on validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.legend([\"Accuracies on train\", \"Accuracies on validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
