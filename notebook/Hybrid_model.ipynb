{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTROL PARAMETERS CELL\n",
    "\n",
    "name = [\"Lagos\",\"Valencia\"]\n",
    "\n",
    "split_size = 0.8\n",
    "batch_size =  32\n",
    "\n",
    "hidden_layers =  4\n",
    "n_layers = hidden_layers + 3\n",
    "input_size = 2**(hidden_layers+1)\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "data = np.load('Dati/dataset_{}_x_{}.npy'.format(name[0],name[1]))\n",
    "label = np.load('Dati/labels_{}_x_{}.npy'.format(name[0],name[1]))\n",
    "data = torch.tensor(data, dtype=torch.float32)\n",
    "label = torch.tensor(label, dtype=torch.float32)\n",
    "label = torch.reshape(label, [label.shape[0], 1])\n",
    "\n",
    "\n",
    "dataset = TensorDataset(data,label)\n",
    "\n",
    "train_size = int(split_size * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockLayer(torch.nn.Module):\n",
    "    def __init__(self,input_feat, output_feat, d_out = 0):\n",
    "        super(BlockLayer,self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Linear( input_feat, output_feat),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout( d_out )\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HybridNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_layers, input_feat, d_out):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        output_feat = int(input_feat/2)\n",
    "        self.layers.append( torch.nn.Linear( len(data[0])  , input_feat) )\n",
    "        self.layers.append(torch.nn.Tanh())\n",
    "        self.layers.append(torch.nn.Dropout(0.3))\n",
    "\n",
    "        for i in range (hidden_layers):\n",
    "            self.layers.append( BlockLayer(input_feat, output_feat, d_out) )\n",
    "            if output_feat == 1: break\n",
    "            input_feat = output_feat\n",
    "            output_feat = int(input_feat*0.8)\n",
    "\n",
    "        self.layers.append( torch.nn.Linear(input_feat , 2) )\n",
    "        self.layers.append(qlayer)\n",
    "        self.layers.append(torch.nn.Linear(2,1))\n",
    "        self.layers.append(torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = HybridNetwork( hidden_layers , input_size, dropout )\n",
    "opt = torch.optim.Adam(hybrid_model.parameters(), learning_rate)\n",
    "lossFunction = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_model( model , loader , loss_fn  ):\n",
    "    \n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disabilitare il calcolo dei gradienti per la valutazione\n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            output = model(data)\n",
    "            label = torch.reshape(label, [label.shape[0], 1])\n",
    "            all_outputs.append(output)\n",
    "            all_labels.append(label)\n",
    "\n",
    "        # Convertire gli output in tensori per applicare softmax\n",
    "        all_outputs_tensor = torch.cat(all_outputs)\n",
    "        all_labels_tensor = torch.cat(all_labels)\n",
    "\n",
    "        # Calcolare la probabilit√† con Softmax per classificazione\n",
    "        output_probs = torch.sigmoid(all_outputs_tensor)\n",
    "        predicted = torch.round(output_probs)\n",
    "    \n",
    "        # Calcolare l'accuratezza\n",
    "        accuracy = accuracy_score(all_labels_tensor.numpy(), predicted.numpy())\n",
    "\n",
    "        # Calcolare la perdita totale\n",
    "        #all_outputs_tensor.requires_grad = True  # Re-enable gradients for loss calculation\n",
    "        loss = lossFunction(all_outputs_tensor, all_labels_tensor).item()\n",
    "\n",
    "        return accuracy , loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual model training (and validation). It may take a while, depending on:\n",
    "# epoch number, network architecture, dataset size.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "# This is the actual model training (and validation). It may take a while, depending on:\n",
    "# epoch number, network architecture, dataset size.\n",
    "\n",
    "train_losses = np.zeros(epochs)\n",
    "val_losses = np.zeros(epochs)\n",
    "\n",
    "train_accuracies = np.zeros(epochs)\n",
    "val_accuracies = np.zeros(epochs)\n",
    "# training the model\n",
    "for i in range(epochs):\n",
    "    training_total_loss = []\n",
    "    hybrid_model.train()  # Set the model to training mode\n",
    "    for id_batch, (data, label) in enumerate(train_loader):\n",
    "   \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        output = hybrid_model(data)\n",
    "        label = torch.reshape(label, [label.shape[0], 1])\n",
    "        loss = lossFunction(output, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        training_total_loss.append(loss.item())\n",
    "\n",
    "    hybrid_model.eval()\n",
    "    train_accuracies[i] , train_losses[i] = evaluate_model( hybrid_model , train_loader, lossFunction)\n",
    "    val_accuracies[i] , val_losses[i] = evaluate_model( hybrid_model , val_loader, lossFunction)\n",
    "      \n",
    "    #scheduler.step()\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {}\\tTraining Loss: {:.4f}\\tVal Loss: {:.4f}\\tTraining Accuracy: {:.2f}%\\tValidation Accuracy: {:.2f}%\".format(\n",
    "            i + 1, train_losses[i], val_losses[i], 100 * train_accuracies[i], 100 * val_accuracies[i]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend([\"Loss on train\", \"Loss on validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.legend([\"Accuracies on train\", \"Accuracies on validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
